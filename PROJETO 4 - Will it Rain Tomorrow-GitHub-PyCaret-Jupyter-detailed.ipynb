{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pyforest auto-imports\n",
    "import warnings\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from pandas_profiling import ProfileReport\n",
    "#import pyforest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFECV as RFECV_SKYLEARN\n",
    "pd.options.display.max_columns = 100\n",
    "#pd.set_option('display.max_columns', None)\n",
    "from IPython.display import Audio, display\n",
    "def allDone():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import key_table\n",
    "rain_aus = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/rain_data_aus.csv\")\n",
    "rain_aus = rain_aus.rename(columns={\"amountOfRain\": \"amntraintmrw\"})\n",
    "rain_aus['raintoday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "rain_aus['raintomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "rain_aus.head()\n",
    "\n",
    "\n",
    "# Import side_tables and concatenate in one\n",
    "wind1 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_01.csv\")\n",
    "wind2 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_02.csv\")\n",
    "wind3= pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_03.csv\")\n",
    "wind4 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_04.csv\")\n",
    "wind5 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_05.csv\")\n",
    "wind6 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_06.csv\")\n",
    "wind7 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_07.csv\")\n",
    "wind8 = pd.read_csv(\"C:/Users/user/Documents/1. GitHub/Projeto 4 - Itau/case_guide/data/wind_table_08.csv\")\n",
    "wind = pd.concat([wind1, wind2, wind3, wind4, wind5, wind6, wind7, wind8])\n",
    "\n",
    "#Correct merged side_tables\n",
    "cont = 2\n",
    "for col in wind.columns[8:14]:\n",
    "    wind.loc[~wind[col].isnull(), wind.columns[cont]] = wind.loc[~wind[col].isnull(), col]\n",
    "    cont +=1\n",
    "wind = wind.drop(['windgustdir', 'windgustspeed', 'winddir9am', 'winddir3pm', 'windspeed9am', 'windspeed3pm'], axis=1)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all tables and apply conditions to correct it\n",
    "rain_merge = pd.merge(left=rain_aus, right=wind, how='left', on=['date', 'location'])\n",
    "rain_merge['date'] = pd.to_datetime(rain_merge['date'].str.strip(), format='%Y/%m/%d')\n",
    "rain_merge.loc[(rain_merge.amntraintmrw < 0.4),'amntraintmrw']=0\n",
    "#Duplicates\n",
    "    #rain_merge.groupby(rain_merge.columns.tolist(),as_index=False).size())\n",
    "\n",
    "allDone()\n",
    "# %% Correct More\n",
    "#Correct type from columns\n",
    "rain_merge['wind_gustdir'] = rain_merge['wind_gustdir'].astype(str)\n",
    "rain_merge['wind_dir9am'] = rain_merge['wind_dir9am'].astype(str)\n",
    "rain_merge['wind_dir3pm'] = rain_merge['wind_dir3pm'].astype(str)\n",
    "#turn it into a scale\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(rain_merge['wind_gustdir'])\n",
    "#transform\n",
    "rain_merge['wind_gustdir'] = encoder.transform(rain_merge['wind_gustdir'])\n",
    "rain_merge['wind_dir9am'] = encoder.transform(rain_merge['wind_dir9am'])\n",
    "rain_merge['wind_dir3pm'] = encoder.transform(rain_merge['wind_dir3pm'])\n",
    "\n",
    "# see min and max from table\n",
    "print(rain_merge['date'].min())\n",
    "print(rain_merge['date'].max())\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish your new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a table by your current season (apply one month ago + actual month + next month)\n",
    "seasoned_rain = rain_merge[(rain_merge['date'].dt.month == 5) | (rain_merge['date'].dt.month == 6) | (rain_merge['date'].dt.month == 7)]\n",
    "seasoned_rain = seasoned_rain[~(seasoned_rain['date'].dt.year <= 2007)]\n",
    "#seasoned_rain = seasoned_rain[~(seasoned_rain['date'].dt.year >= 2017)]\n",
    "\n",
    "#Your pipeline to clean your data for your problem and manage it:\n",
    "#seasoned_rain.drop(['raintomorrow', 'amntraintmrw', 'modelo_vigente', 'temp', 'temp9am', 'temp3pm', 'humidity'], axis=1)\n",
    "\n",
    "allDone()\n",
    "# %% See result\n",
    "seasoned_rain['raintomorrow'].value_counts()\n",
    "seasoned_rain.info()\n",
    "seasoned_rain\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL IT: PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "clf1 = setup(data = seasoned_rain, target = 'raintomorrow'\n",
    "             , silent = True\n",
    "             , log_experiment = True, experiment_name = 'rain_tomorrow_exp'\n",
    "             , log_plots = True, log_profile = True, log_data = True\n",
    "             #, profile = True #, profile_kwargs = True\n",
    "             , train_size = 0.3\n",
    "             #, sampling = True\n",
    "             , numeric_imputation = 'median', categorical_imputation = 'constant'\n",
    "             , normalize = True, normalize_method = 'zscore'\n",
    "             , handle_unknown_categorical = True, unknown_categorical_method = 'most_frequent'\n",
    "             , fix_imbalance = True\n",
    "             , transformation = True, transformation_method = 'yeo-johnson'\n",
    "             , combine_rare_levels = True, rare_level_threshold = 0.1\n",
    "             , feature_selection = True, feature_selection_threshold = 0.8\n",
    "             , remove_multicollinearity = True, multicollinearity_threshold = 0.95\n",
    "             , pca = False\n",
    "             , ignore_low_variance = True\n",
    "             , fold_strategy = 'stratifiedkfold'\n",
    "             , fold = 10\n",
    "             , use_gpu = False\n",
    "              )\n",
    "\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = seasoned_rain\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = seasoned_rain.sample(frac=0.95, random_state=786)\n",
    "data_unseen = seasoned_rain.drop(data.index)\n",
    "\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "data_unseen.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unseen Data For Predictions ' + str(data_unseen.shape))\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return best model\n",
    "best = compare_models(sort = 'AUC') #default is 'Accuracy'\n",
    "allDone()\n",
    "print(best)\n",
    "allDone()\n",
    "\n",
    "save_model(best, 'best')\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return top 3 models based on 'Accuracy'\n",
    "top3 = compare_models(n_select = 3, sort = 'Prec.', round = 2)\n",
    "allDone()\n",
    "print(top3)\n",
    "allDone()\n",
    "# compare specific models\n",
    "#best_specific = compare_models(include = ['dt','rf','xgboost'])\n",
    "# blacklist certain models\n",
    "#best_specific = compare_models(exclude = ['catboost', 'svm'])\n",
    "\n",
    "save_model(top3, 'top3')\n",
    "allDone()\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(best,fold = 10)\n",
    "plot_model(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = pull()\n",
    "top3_results = pull()\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = tune_model(best, optimize = 'Prec.', n_iter = 50)\n",
    "allDone()\n",
    "plot_model(tuned_model)\n",
    "allDone()\n",
    "\n",
    "save_model(tuned_model, 'tuned_model')\n",
    "allDone()\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model, plot = 'parameter')\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Boosting\n",
    "boosted_tuned_model = ensemble_model(tuned_model, method = 'Boosting', n_estimators = 100)\n",
    "allDone()\n",
    "plot_model(boosted_tuned_model)\n",
    "allDone()\n",
    "print(boosted_tuned_model.estimators_)\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "save_model(boosted_tuned_model, 'boosted_tuned_model')\n",
    "allDone()\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend Models\n",
    "blender = blend_models(top3)\n",
    "plot_model(blender)\n",
    "allDone()\n",
    "print(blender.estimators_)\n",
    "allDone()\n",
    "\n",
    "save_model(blender, 'blender')\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "blender_specific = blend_models(estimator_list = compare_models(n_select = 3), method = 'hard')\n",
    "allDone()\n",
    "plot_model(blender_specific)\n",
    "allDone()\n",
    "print(blender_specific.estimators_)\n",
    "allDone()\n",
    "\n",
    "\n",
    "save_model(blender_specific, 'blender_specific')\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Model\n",
    "stacker_top3 = stack_models(estimator_list = top3[1:], meta_model = top3[0])\n",
    "allDone()\n",
    "plot_model(stacker_top3)\n",
    "allDone()\n",
    "print(stacker_top3.estimators_)\n",
    "allDone()\n",
    "\n",
    "\n",
    "save_model(stacker_top3, 'stacker_top3')\n",
    "allDone()\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Bagging\n",
    "bagged_tuned_model = ensemble_model(tuned_model, method = 'Bagging', n_estimators = 100)\n",
    "allDone()\n",
    "plot_model(bagged_tuned_model)\n",
    "allDone()\n",
    "print(bagged_tuned_model.estimators_)\n",
    "\n",
    "save_model(bagged_tuned_model, 'bagged_tuned_model')\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Calibrate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(boosted_tuned_model, plot='calibration')\n",
    "allDone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_boosted_tuned_model = calibrate_model(boosted_tuned_model)\n",
    "allDone()\n",
    "plot_model(calibrated_boosted_tuned_model, plot='calibration')\n",
    "allDone()\n",
    "print(calibrated_boosted_tuned_model.estimators_)\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "save_model(calibrated_boosted_tuned_model, 'calibrated_boosted_tuned_model')\n",
    "allDone()\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_boosted_tuned_model_isotonic = calibrate_model(boosted_tuned_model, method = 'isotonic')\n",
    "allDone()\n",
    "plot_model(calibrated_boosted_tuned_model_isotonic, plot='calibration')\n",
    "allDone()\n",
    "print(calibrated_boosted_tuned_model_isotonic.estimators_)\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "save_model(calibrated_boosted_tuned_model_isotonic, 'calibrated_boosted_tuned_model_isotonic')\n",
    "allDone()\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(calibrated_boosted_tuned_model)\n",
    "plot_model(calibrated_boosted_tuned_model, plot='error')\n",
    "plot_model(calibrated_boosted_tuned_model, plot='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_threshold(calibrated_boosted_tuned_model, true_negative = 1500, false_negative = -5000)\n",
    "allDone()\n",
    "print(calibrated_tuned_model_isotonic.estimators_)\n",
    "logs = get_logs(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdout_calibrated_boosted_tuned_model = predict_model(calibrated_boosted_tuned_model, probability_threshold = 0.1949)\n",
    "allDone()\n",
    "\n",
    "\n",
    "save_model(pred_holdout_calibrated_boosted_tuned_model, 'pred_holdout_calibrated_boosted_tuned_model')\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(calibrated_boosted_tuned_model, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(pred_holdout_calibrated_boosted_tuned_model, importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_calibrated_boosted_tuned_model = finalize_model(calibrated_boosted_tuned_model)\n",
    "allDone()\n",
    "save_model(final_calibrated_boosted_tuned_model, 'final_calibrated_boosted_tuned_model')\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n",
    "get_system_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Mflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See MLflow\n",
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(tuned_model)\n",
    "allDone()\n",
    "interpret_model(tuned_model, plot = 'correlation')\n",
    "allDone()\n",
    "interpret_model(tuned_model, plot = 'reason', observation = 10)\n",
    "allDone()\n",
    "logs = get_logs(save=True)\n",
    "\n",
    "get_system_logs()\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "shap.initjs()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=2, importance_type='gain', colsample_bytree=0.3)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "explainer\n",
    "\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgb.predict_proba(X_test)[:, 1], columns=['prob']).query('0.2 < prob < 0.6 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rainy Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_value = explainer.expected_value\n",
    "shap.force_plot(expected_value, shap_values[80],features= X.iloc[80], link='logit',feature_names=X.columns, show=False)#.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(expected_value, shap_values[:80], X.iloc[:80], link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(base_value, shap_values[80], X_test.iloc[80], highlight=0, link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sunny Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_value = explainer.expected_value\n",
    "shap.force_plot(expected_value, shap_values[802],features= X.iloc[802], link='logit',feature_names=X.columns, show=False)#.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(base_value, shap_values[802], X_test.iloc[802], highlight=0, link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(expected_value, shap_values[:802], X.iloc[:802], link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
